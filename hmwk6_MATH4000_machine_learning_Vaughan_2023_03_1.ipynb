{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e9aaf7",
   "metadata": {},
   "source": [
    "#  David Vaughan  R1166390\n",
    "# (MATH-4000-004)\n",
    "# Homework 6 02/22/2023\n",
    "#  Spring 2023 TTU Selected Topics: Machine learning model order reduction for differential equations (MATH-4000-004) Full Term: Homework for week  (due 03/01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55128a7",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "LeNet is an early convolutional neural network structure proposed by LeCun et al. in 1998. Read more details in LeNet in https://en.wikipedia.org/wiki/LeNet and implement LeNet (see the picture below, the LeNet structure on the left) by modifying the code in the lecture note \"lecture-05-code-part1\". Report the accuracy of the LeNet.\n",
    "\n",
    "Some useful hints:\n",
    "1. You need to modify the class CNNModel(nn.Module) in Step 3).\n",
    "2. \"Dense: 120 fully connected neurons\" in the picture refers to the linear layer in feedforward neural network. The output dimension is 120 and the input dimension is determined by the previous layer.\n",
    "\n",
    "![convert notebook to web app](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/480px-Comparison_image_neural_networks.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ba43e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5d19fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fce9c82130>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJEElEQVR4nO3cOWhV6x7G4bWvwULRSBoFQUQLRUVsVDgIIiIiaBG1CVgpVgpWNnYWEcGhCFqkCtiIpUOjhVMhCOLQBOyVdBqNM5p9m8vLKS7c/Ne5GYzPU6+XtRCyf3yFX6fb7XYbAGia5l+z/QEAzB2iAECIAgAhCgCEKAAQogBAiAIAIQoARM9UH+x0OtP5HQBMs6n8X2UnBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAome2PwD+lwULFpQ3vb290/Al/x8nT55stVu0aFF5s27duvLmxIkT5c3FixfLm4GBgfKmaZrm27dv5c358+fLm7Nnz5Y384GTAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4EG+eWbVqVXmzcOHC8uavv/4qb3bs2FHeNE3TLFu2rLw5dOhQq3fNN2/evClvhoaGypv+/v7yZmJiorxpmqZ59epVefPo0aNW7/oTOSkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoARKfb7Xan9GCnM93fwt9s2bKl1e7+/fvlTW9vb6t3MbMmJyfLm6NHj5Y3nz59Km/aGBsba7V7//59efP69etW75pvpvJz76QAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQLgldY7q6+trtXv69Gl5s2bNmlbvmm/a/NuNj4+XN7t27SpvmqZpfvz4Ud64AZe/c0sqACWiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAETPbH8A/927d+9a7U6fPl3e7N+/v7x58eJFeTM0NFTetPXy5cvyZs+ePeXN58+fy5uNGzeWN03TNKdOnWq1gwonBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYDodLvd7pQe7HSm+1uYJUuXLi1vJiYmypvh4eHypmma5tixY+XNkSNHypvr16+XN/A7mcrPvZMCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQPTM9gcw+z5+/Dgj7/nw4cOMvKdpmub48ePlzY0bN8qbycnJ8gbmMicFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAKLT7Xa7U3qw05nub2GeW7x4cavd7du3y5udO3eWN/v27Stv7t27V97AbJnKz72TAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4EI85b+3ateXN8+fPy5vx8fHy5sGDB+XNs2fPypumaZqrV6+WN1P88+YP4UI8AEpEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgX4jEv9ff3lzcjIyPlzZIlS8qbts6cOVPeXLt2rbwZGxsrb/g9uBAPgBJRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAMKFePAfmzZtKm8uX75c3uzevbu8aWt4eLi8GRwcLG/evn1b3jDzXIgHQIkoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFCPPgHli1bVt4cOHCg1btGRkbKmzZ/t/fv3y9v9uzZU94w81yIB0CJKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEW1LhN/H9+/fypqenp7z5+fNnebN3797y5uHDh+UN/4xbUgEoEQUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAg6rdlwTy1efPm8ubw4cPlzdatW8ubpml3uV0bo6Oj5c3jx4+n4UuYDU4KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFCPOa8devWlTcnT54sbw4ePFjerFixoryZSb9+/SpvxsbGypvJycnyhrnJSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgXIhHK20ughsYGGj1rjaX261evbrVu+ayZ8+elTeDg4Plza1bt8ob5g8nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwId48s3z58vJmw4YN5c2VK1fKm/Xr15c3c93Tp0/LmwsXLrR6182bN8ubycnJVu/iz+WkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4JXUG9PX1lTfDw8Ot3rVly5byZs2aNa3eNZc9efKkvLl06VJ5c/fu3fLm69ev5Q3MFCcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgPijL8Tbvn17eXP69OnyZtu2beXNypUry5u57suXL612Q0ND5c25c+fKm8+fP5c3MN84KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEH30hXn9//4xsZtLo6Gh5c+fOnfLm58+f5c2lS5fKm6ZpmvHx8VY7oM5JAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACA63W63O6UHO53p/hYAptFUfu6dFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA6Jnqg91udzq/A4A5wEkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA+DdFFDZD3G7ZOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img, label = train_dataset[0]\n",
    "print(img)\n",
    "print(img.shape)\n",
    "print(label)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c0da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6cc7e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "02ef58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel2, self).__init__()\n",
    "        # input matrix img 28 height x28 witdth x1 channel;\n",
    "        #################################\n",
    "        # 5x5 kernel+2padding:28x28x6\n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)\n",
    "        #Sigmoid(x)=σ(x)=1/( 1+exp(−x) )\n",
    "        #\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        #self.sigmoid1 = nn.ReLU()\n",
    "        #2x2 kernel+2 stride:14x14x6\n",
    "        # Max pool 1\n",
    "        #AvgPool2d\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        #self.maxpool1 = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        # 5x5 kernel+no  padding:10x10x16\n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        #self.sigmoid2 = nn.ReLU()\n",
    "        # 2x2 kernel+2 stride:5x5x6\n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        #self.maxpool2 = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        # Fully connected 1 (readout)\n",
    "        #################################\n",
    "        # flatten 16 output channel of 5x5 img, to 120 nuerons\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 10) \n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 5*5) \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) \n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 16 * 5 * 5) \n",
    "        ##############################################################################################\n",
    "        #DENSE\n",
    "        # USE FNN        \n",
    "        #self.hidden_layer1 = torch.nn.Linear(120, 120)\n",
    "        #self.hidden_layer2 = torch.nn.Linear(120, 84)\n",
    "        #self.output_layer  = torch.nn.Linear(84, 10)\n",
    "        self.sig3 = nn.Sigmoid()\n",
    "        #self.sig3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.sig4 = nn.Sigmoid()\n",
    "        #self.sig4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self, x):\n",
    "        # input: x, size (num_img, 28, 28)\n",
    "        # Convolution 1\n",
    "        # O = (28 - 5 + 2*2)/ 1 + 1 = 28\n",
    "        # output: size (num_img, 16, 28, 28)\n",
    "        out = self.cnn1(x)\n",
    "        out = self.sigmoid1(out)\n",
    "        # Max pool 1\n",
    "        # O = 28 / 2 = 14\n",
    "        # output: size (num_img, 16, 14, 14)\n",
    "        out = self.maxpool1(out)\n",
    "        # Convolution 2\n",
    "        # O = (14 - 5 + 2*2)/ 1 + 1 = 14\n",
    "        # output: size (num_img, 32, 14, 14)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.sigmoid2(out)\n",
    "        # Max pool 2\n",
    "        # O = 14 / 2 = 7\n",
    "        # output: size (num_img, 32, 7, 7)\n",
    "        out = self.maxpool2(out)\n",
    "        # Resize\n",
    "        # Original size: (num_img, 32, 7, 7)\n",
    "        # out.size(0): num_img\n",
    "        # New out size: (num_img, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Linear function (readout)\n",
    "        # output: size (num_img, 10)\n",
    "        out = self.fc1(out)\n",
    "        #return out\n",
    "        # input layer\n",
    "        z = out\n",
    "#################### FNN PART\n",
    "        # hidden layer 1\n",
    "        # z = W_1 * z + b_1\n",
    "        # torch.nn.Linear(16 * 5 * 5, 120)\n",
    "        # W_1: \n",
    "        # b_1: \n",
    "        #z = self.hidden_layer1(z)\n",
    "        # z = ReLU(z)\n",
    "        #z = torch.sigmoid(z)\n",
    "        #z = torch.tanh(z)\n",
    "        out = self.sig3(out)\n",
    "        out = self.fc2(out)\n",
    "        # hidden layer 2\n",
    "        # z = W_2 * z + b_2\n",
    "        #torch.nn.Linear(120, 84)\n",
    "        # W_2: \n",
    "        # b_2:         \n",
    "        #z = self.hidden_layer2(z)\n",
    "        # z = ReLU(z)\n",
    "        #z = torch.sigmoid(z)\n",
    "        #z = torch.tanh(z)\n",
    "        out = self.sig4(out)\n",
    "        # output layer\n",
    "        # z = W_3 * z + b_3\n",
    "        #torch.nn.Linear(84, 10)\n",
    "        # W_3: \n",
    "        # b_3: \n",
    "        #z = self.output_layer(z)      \n",
    "        # z: 1\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0ab7ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = CNNModel2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "afdfd839",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "669552a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "#learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "005fffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 2.3352553844451904. Accuracy: 11.350000381469727\n",
      "Iteration: 1000. Loss: 2.3009026050567627. Accuracy: 11.350000381469727\n",
      "Iteration: 1500. Loss: 2.332962989807129. Accuracy: 11.350000381469727\n",
      "Iteration: 2000. Loss: 2.326007604598999. Accuracy: 11.350000381469727\n",
      "Iteration: 2500. Loss: 2.315483331680298. Accuracy: 11.350000381469727\n",
      "Iteration: 3000. Loss: 2.3221731185913086. Accuracy: 11.350000381469727\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images\n",
    "        images = images.requires_grad_()\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model2(images)\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        iter += 1\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images\n",
    "                images = images.requires_grad_()\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model2(images)\n",
    "                #print(outputs.size())\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100 * correct / total\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e844067",
   "metadata": {},
   "source": [
    "### SPARE/Unecssary CODE at Bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e731f7",
   "metadata": {},
   "source": [
    " The code for this assignment looks ok to me but I also feel like i did something wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61b80ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noutput_size_end = 10\\n        \\n        # number of layers\\n        num_layers = 3\\n        \\n        # number of neurons in the hidden layers\\n        # first layer\\n        hidden_size1 = 120\\n        #second\\n        hidden_size2 = 84\\n        #\\n        hidden_size3 = 10\\n        \\n        # activation functions\\n        self.activiation = activiation\\n        \\n        # first hidden layer\\n        self.layers = torch.nn.ModuleList([torch.nn.Linear(input_size, hidden_size1)])\\n        # hidden layers inside the neural network\\n        self.layers.extend([torch.nn.Linear(hidden_size1, hidden_size2) for i in range(1, 3-1)])\\n        # output layer\\n        self.layers.append(torch.nn.Linear(hidden_size3, output_size_end))\\n        \\n        # activation function list: relu, tanh\\n        self.act_list = {'relu': torch.nn.ReLU(), 'tanh': torch.nn.Tanh()}\\n        self.act_func = self.act_list[self.activiation]\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "output_size_end = 10\n",
    "        \n",
    "        # number of layers\n",
    "        num_layers = 3\n",
    "        \n",
    "        # number of neurons in the hidden layers\n",
    "        # first layer\n",
    "        hidden_size1 = 120\n",
    "        #second\n",
    "        hidden_size2 = 84\n",
    "        #\n",
    "        hidden_size3 = 10\n",
    "        \n",
    "        # activation functions\n",
    "        self.activiation = activiation\n",
    "        \n",
    "        # first hidden layer\n",
    "        self.layers = torch.nn.ModuleList([torch.nn.Linear(input_size, hidden_size1)])\n",
    "        # hidden layers inside the neural network\n",
    "        self.layers.extend([torch.nn.Linear(hidden_size1, hidden_size2) for i in range(1, 3-1)])\n",
    "        # output layer\n",
    "        self.layers.append(torch.nn.Linear(hidden_size3, output_size_end))\n",
    "        \n",
    "        # activation function list: relu, tanh\n",
    "        self.act_list = {'relu': torch.nn.ReLU(), 'tanh': torch.nn.Tanh()}\n",
    "        self.act_func = self.act_list[self.activiation]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2ecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68bc9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedforward neural network with 2 hidden layers\n",
    "####MOVE AWAY LATER\n",
    "class FNNTwoHiddenLayerSig(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FNNTwoHiddenLayerSig, self).__init__()    \n",
    "        \n",
    "        self.hidden_layer1 = torch.nn.Linear(120, 120)\n",
    "        self.hidden_layer2 = torch.nn.Linear(84, 84)\n",
    "        self.output_layer  = torch.nn.Linear(84, 10)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input layer\n",
    "        z = x\n",
    "        \n",
    "        # hidden layer 1\n",
    "        # z = W_1 * z + b_1\n",
    "        # W_1: 10 * 1\n",
    "        # b_1: 10 * 1\n",
    "        z = self.hidden_layer1(z)\n",
    "        # z = ReLU(z)\n",
    "        z = torch.sigmoid(z)\n",
    "\n",
    "        # hidden layer 2\n",
    "        # z = W_2 * z + b_2\n",
    "        # W_2: 10 * 10\n",
    "        # b_2: 10 * 1        \n",
    "        z = self.hidden_layer2(z)\n",
    "        # z = ReLU(z)\n",
    "        z = torch.sigmoid(z)\n",
    "        \n",
    "        # output layer\n",
    "        # z = W_3 * z + b_3\n",
    "        # W_3: 1 * 10\n",
    "        # b_3: 1\n",
    "        z = self.output_layer(z)\n",
    "        \n",
    "        # z: 1\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9b327b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# feedforward neural network with arbitrary number of layers\n",
    "class FNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, num_layers, hidden_size, activiation):\n",
    "        super(FNN, self).__init__()\n",
    "        \n",
    "        # dimension of the input data: x\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # dimension of the output data: y\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # number of layers\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # number of neurons in the hidden layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # activation functions\n",
    "        self.activiation = activiation\n",
    "        \n",
    "        # first hidden layer\n",
    "        self.layers = torch.nn.ModuleList([torch.nn.Linear(input_size, hidden_size)])\n",
    "        # hidden layers inside the neural network\n",
    "        self.layers.extend([torch.nn.Linear(hidden_size, hidden_size) for i in range(1, self.num_layers-1)])\n",
    "        # output layer\n",
    "        self.layers.append(torch.nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        # activation function list: relu, tanh\n",
    "        self.act_list = {'relu': torch.nn.ReLU(), 'tanh': torch.nn.Tanh(),'sig':torch.nn.Sigmoid()}\n",
    "        self.act_func = self.act_list[self.activiation]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input layer\n",
    "        z = x\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            \n",
    "            if i < (self.num_layers-1):\n",
    "                # hidden layer\n",
    "                # linear layer: z = W_i * z + b_i\n",
    "                z = self.layers[i](z)\n",
    "                # nonlinear layer: z = sigma(z)\n",
    "                z = self.act_func(z)\n",
    "            \n",
    "            else:\n",
    "                # output layer\n",
    "                # linear layer: z = W_i * z + b_i\n",
    "                z = self.layers[i](z)\n",
    "                \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "23e778cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        #input matrix img 28 height x28 witdth x1 channel;\n",
    "        #################################\n",
    "        #5x5 kernel+2padding:28x28x6\n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)\n",
    "        #Sigmoid(x)=σ(x)=1/( 1+exp(−x) )\n",
    "        #\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "\n",
    "        #2x2 kernel+2 stride:14x14x6\n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        #5x5 kernel+no  padding:10x10x16\n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "\n",
    "        #2x2 kernel+2 stride:5x5x6\n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        # Fully connected 1 (readout)\n",
    "        #################################\n",
    "        # flatten 16 output channel of 5x5 img, to 120 nuerons\n",
    "        \n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 10) \n",
    "        ##self.fc1 = nn.Linear(16 * 5 * 5, 5*5) \n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 16 * 5 * 5) \n",
    "        ##############################################################################################\n",
    "        #DENSE\n",
    "        # USE FNN        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input: x, size (num_img, 28, 28)\n",
    "        \n",
    "        # Convolution 1\n",
    "        # O = (28 - 5 + 2*2)/ 1 + 1 = 28\n",
    "        # output: size (num_img, 16, 28, 28)\n",
    "        out = self.cnn1(x)\n",
    "        out = self.sigmoid1(out)\n",
    "\n",
    "        # Max pool 1\n",
    "        # O = 28 / 2 = 14\n",
    "        # output: size (num_img, 16, 14, 14)\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # Convolution 2\n",
    "        # O = (14 - 5 + 2*2)/ 1 + 1 = 14\n",
    "        # output: size (num_img, 32, 14, 14)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.sigmoid2(out)\n",
    "\n",
    "        # Max pool 2\n",
    "        # O = 14 / 2 = 7\n",
    "        # output: size (num_img, 32, 7, 7)\n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        # Resize\n",
    "        # Original size: (num_img, 32, 7, 7)\n",
    "        # out.size(0): num_img\n",
    "        # New out size: (num_img, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        # output: size (num_img, 10)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "434b64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "model = CNNModel()\n",
    "#fcn1 = FNN(input_size=10, output_size=120, num_layers=1, hidden_size=120, activiation='sig')\n",
    "#fcn1 = FNN(input_size=120, output_size=120, num_layers=1, hidden_size=120, activiation='sig')\n",
    "fcn1 = FNN(input_size=16 * 5 * 5, output_size=120, num_layers=1, hidden_size=120, activiation='sig')\n",
    "fcn2 = FNN(input_size=120, output_size=84, num_layers=1, hidden_size=84, activiation='sig')\n",
    "fcn3 = FNN(input_size=84, output_size=10, num_layers=1, hidden_size=10, activiation='sig')\n",
    "#fnn2 = FNNTwoHiddenLayerSig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86573f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a626b7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 2.3153538703918457. Accuracy: 9.819999694824219\n",
      "Iteration: 1000. Loss: 2.326113224029541. Accuracy: 9.819999694824219\n",
      "Iteration: 1500. Loss: 2.357224702835083. Accuracy: 9.819999694824219\n",
      "Iteration: 2000. Loss: 2.383333206176758. Accuracy: 9.819999694824219\n",
      "Iteration: 2500. Loss: 2.4442083835601807. Accuracy: 9.819999694824219\n",
      "Iteration: 3000. Loss: 2.3877065181732178. Accuracy: 9.819999694824219\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images\n",
    "        images = images.requires_grad_()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        #outputs = model(images)\n",
    "        outputs = model2(images)\n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        #print(\"conv\")\n",
    "        #print(outputs.size())\n",
    "        \n",
    "        #do FNN dense 120 layer\n",
    "        #outputs = fnn2(outputs)\n",
    "        #outputs = fcn1(outputs)\n",
    "        #print(\"fnn1\")\n",
    "        #print(outputs.size())\n",
    "        # 84\n",
    "        #outputs = fcn2(outputs)\n",
    "        #print(\"fnn2\")\n",
    "        #print(outputs.size())\n",
    "        #10\n",
    "        #outputs = fcn3(outputs)\n",
    "        #print(\"fnn3\")\n",
    "        #print(outputs.size())\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images\n",
    "                images = images.requires_grad_()\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                #outputs = model(images)\n",
    "                outputs = model2(images)\n",
    "                #print(\"conv\")\n",
    "                #print(outputs.size())\n",
    "                \n",
    "                #do FNN dense 120 layer\n",
    "                \n",
    "                #outputs = fnn2(outputs)\n",
    "                #outputs = fcn1(outputs)\n",
    "                #print(\"fnn1\")\n",
    "                #print(outputs.size())\n",
    "                # 84\n",
    "                #outputs = fcn2(outputs)\n",
    "                #print(\"fnn2\")\n",
    "                #print(outputs.size())\n",
    "                #10\n",
    "                #outputs = fcn3(outputs)\n",
    "                #print(\"fnn3\")\n",
    "                #print(outputs.size())\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
